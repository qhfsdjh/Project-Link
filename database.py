"""
é«˜æ€§èƒ½æ•°æ®åº“ç®¡ç†æ¨¡å—
ä½¿ç”¨ SQLite3 å’Œ contextlib è¿›è¡Œèµ„æºç®¡ç†
"""

import sqlite3
import contextlib
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Tuple, Any
from pathlib import Path
from utils.logger import get_logger  # å¯¼å…¥æ—¥å¿—æ¨¡å—

# åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
logger = get_logger("database")

# å¯¼å…¥é…ç½®ï¼ˆå»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯ä¾èµ–ï¼‰
_config = None

def _get_config():
    """å»¶è¿Ÿå¯¼å…¥é…ç½®æ¨¡å—"""
    global _config
    if _config is None:
        import config
        _config = config
    return _config


# æ•°æ®åº“æ–‡ä»¶è·¯å¾„
DB_PATH = Path("app.db")


def get_column_names(table_name: str) -> List[str]:
    """
    è·å–è¡¨çš„åˆ—ååˆ—è¡¨ï¼ˆä½¿ç”¨ PRAGMA é¢„æ£€ï¼‰
    
    Args:
        table_name: è¡¨å
    
    Returns:
        åˆ—ååˆ—è¡¨
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute(f"PRAGMA table_info({table_name})")
        return [row[1] for row in cursor.fetchall()]


def get_current_time() -> str:
    """
    è·å–å½“å‰æ—¶é—´ï¼ˆISO æ ¼å¼ï¼Œå¸¦æ—¶åŒºä¿¡æ¯ï¼‰
    å¦‚æœ PL_TIMEZONE é…ç½®ä¸ºç©ºï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ—¶åŒº
    
    Returns:
        ISO æ ¼å¼æ—¶é—´å­—ç¬¦ä¸²ï¼ˆå¸¦æ—¶åŒºä¿¡æ¯ï¼‰
    """
    config = _get_config()
    
    if config.PL_TIMEZONE:
        # ä½¿ç”¨æŒ‡å®šçš„æ—¶åŒº
        try:
            # Python 3.9+ ä½¿ç”¨ zoneinfo
            from zoneinfo import ZoneInfo
            return datetime.now(ZoneInfo(config.PL_TIMEZONE)).isoformat()
        except ImportError:
            # Python < 3.9ï¼Œå°è¯•ä½¿ç”¨ pytzï¼ˆå¯é€‰ä¾èµ–ï¼‰
            try:
                import pytz  # type: ignore  # å¯é€‰ä¾èµ–ï¼Œå¯èƒ½æœªå®‰è£…
                tz = pytz.timezone(config.PL_TIMEZONE)
                return datetime.now(tz).isoformat()
            except ImportError:
                logger.warning("æ—¶åŒºåº“ä¸å¯ç”¨ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ—¶åŒº")
                return datetime.now().astimezone().isoformat()
    else:
        # ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ—¶åŒºï¼ˆå¸¦æ—¶åŒºä¿¡æ¯ï¼‰
        return datetime.now().astimezone().isoformat()


@contextlib.contextmanager
def get_db_connection():
    """
    æ•°æ®åº“è¿æ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    è‡ªåŠ¨å¤„ç†äº‹åŠ¡æäº¤å’Œå›æ»šï¼Œç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾
    """
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    # å¯ç”¨ WAL æ¨¡å¼ä»¥æé«˜å¹¶å‘æ€§èƒ½
    conn.execute("PRAGMA journal_mode=WAL")
    # ä¼˜åŒ– SQLite æ€§èƒ½è®¾ç½®
    conn.execute("PRAGMA synchronous=NORMAL")
    conn.execute("PRAGMA cache_size=10000")
    conn.execute("PRAGMA temp_store=MEMORY")
    # å¯ç”¨å¤–é”®çº¦æŸ
    conn.execute("PRAGMA foreign_keys=ON")
    
    try:
        yield conn
        conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        conn.close()


def init_db():
    """
    åˆå§‹åŒ–æ•°æ®åº“ï¼Œåˆ›å»ºæ‰€æœ‰è¡¨ç»“æ„
    å¦‚æœè¡¨å·²å­˜åœ¨åˆ™è·³è¿‡ï¼ˆä½¿ç”¨ IF NOT EXISTSï¼‰
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        # åˆ›å»º tasks è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS tasks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                content TEXT NOT NULL,
                due_time TEXT,
                category TEXT,
                priority INTEGER CHECK(priority >= 1 AND priority <= 5) DEFAULT 3,
                status TEXT CHECK(status IN ('pending', 'done', 'ignored', 'cancelled')) DEFAULT 'pending',
                created_at TEXT NOT NULL DEFAULT (datetime('now'))
            )
        """)
        
        # åˆ›å»º preferences è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS preferences (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                key TEXT UNIQUE NOT NULL,
                value TEXT NOT NULL,
                confidence REAL DEFAULT 0.5 CHECK(confidence >= 0.0 AND confidence <= 1.0),
                source TEXT CHECK(source IN ('ç”¨æˆ·ç›´è¯´', 'AIæ¨æ–­')) DEFAULT 'AIæ¨æ–­',
                updated_at TEXT NOT NULL DEFAULT (datetime('now'))
            )
        """)
        
        # åˆ›å»º memory_logs è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS memory_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                content TEXT NOT NULL,
                sentiment TEXT CHECK(sentiment IN ('positive', 'neutral', 'negative')),
                context_tag TEXT,
                timestamp TEXT NOT NULL DEFAULT (datetime('now'))
            )
        """)
        
        # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_tasks_status 
            ON tasks(status)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_tasks_due_time 
            ON tasks(due_time)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_tasks_category 
            ON tasks(category)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_preferences_key 
            ON preferences(key)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_preferences_confidence 
            ON preferences(confidence)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_memory_logs_timestamp 
            ON memory_logs(timestamp)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_memory_logs_context_tag 
            ON memory_logs(context_tag)
        """)
        
        conn.commit()
        logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
        # æ‰§è¡Œæ•°æ®åº“è¿ç§»ï¼ˆæ·»åŠ æ–°å­—æ®µï¼‰
        migrate_database()


def migrate_database():
    """
    æ•°æ®åº“è¿ç§»å‡½æ•°ï¼ˆä½¿ç”¨é¢„æ£€æ¨¡å¼ï¼Œé¿å…å¼‚å¸¸æ§åˆ¶æµï¼‰
    å®‰å…¨åœ°æ·»åŠ æ–°å­—æ®µï¼Œä¸ä¸¢å¤±ç°æœ‰æ•°æ®
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        # 1. é¢„æ£€ï¼šè·å–ç°æœ‰å­—æ®µ
        tasks_columns = get_column_names("tasks")
        prefs_columns = get_column_names("preferences")
        memory_columns = get_column_names("memory_logs")
        
        logger.info("å¼€å§‹æ•°æ®åº“è¿ç§»æ£€æŸ¥...")
        
        # 2. è¿ç§» tasks è¡¨
        # 2.1 ç¡¬åŒ–ï¼šæ‰©å±• tasks.status æ”¯æŒ cancelledï¼ˆSQLite æ— æ³•ç›´æ¥ ALTER CHECKï¼Œéœ€é‡å»ºè¡¨ï¼‰
        _migrate_tasks_status_check(cursor)

        if "last_notified_at" not in tasks_columns:
            cursor.execute("ALTER TABLE tasks ADD COLUMN last_notified_at TEXT")
            logger.info("âœ… å·²æ·»åŠ  tasks.last_notified_at å­—æ®µ")
        else:
            logger.debug("tasks.last_notified_at å­—æ®µå·²å­˜åœ¨ï¼Œè·³è¿‡")
        
        if "notification_count" not in tasks_columns:
            cursor.execute("ALTER TABLE tasks ADD COLUMN notification_count INTEGER DEFAULT 0")
            logger.info("âœ… å·²æ·»åŠ  tasks.notification_count å­—æ®µ")
        else:
            logger.debug("tasks.notification_count å­—æ®µå·²å­˜åœ¨ï¼Œè·³è¿‡")
        
        # 3. è¿ç§» preferences è¡¨
        if "created_at" not in prefs_columns:
            cursor.execute("ALTER TABLE preferences ADD COLUMN created_at TEXT")
            # ä¸ºç°æœ‰è®°å½•è¡¥å…¨ created_atï¼ˆç­‰äº updated_atï¼‰
            cursor.execute("""
                UPDATE preferences 
                SET created_at = updated_at 
                WHERE created_at IS NULL AND updated_at IS NOT NULL
            """)
            updated_count = cursor.rowcount
            logger.info(f"âœ… å·²æ·»åŠ  preferences.created_at å­—æ®µï¼Œå¹¶è¡¥å…¨äº† {updated_count} æ¡æ—§æ•°æ®")
        else:
            logger.debug("preferences.created_at å­—æ®µå·²å­˜åœ¨ï¼Œè·³è¿‡")
        
        # 4. è¿ç§» memory_logs è¡¨
        if "is_processed" not in memory_columns:
            cursor.execute("ALTER TABLE memory_logs ADD COLUMN is_processed INTEGER DEFAULT 0")
            logger.info("âœ… å·²æ·»åŠ  memory_logs.is_processed å­—æ®µ")
        else:
            logger.debug("memory_logs.is_processed å­—æ®µå·²å­˜åœ¨ï¼Œè·³è¿‡")
        
        # 5. åˆ›å»ºæ–°ç´¢å¼•
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_tasks_last_notified_at 
            ON tasks(last_notified_at)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_tasks_notification_count 
            ON tasks(notification_count)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_memory_logs_is_processed 
            ON memory_logs(is_processed)
        """)
        
        conn.commit()
        logger.info("æ•°æ®åº“è¿ç§»å®Œæˆ")
        
        # 6. éªŒè¯è¿ç§»ç»“æœ
        verify_migration()


def _migrate_tasks_status_check(cursor: sqlite3.Cursor) -> None:
    """
    æ‰©å±• tasks.status çš„ CHECK çº¦æŸä»¥æ”¯æŒ 'cancelled'

    SQLite ä¸æ”¯æŒç›´æ¥ä¿®æ”¹ CHECK çº¦æŸï¼Œå› æ­¤é‡‡ç”¨â€œé‡å»ºè¡¨â€æ–¹å¼ï¼š
    - tasks_new ä½¿ç”¨æ–°çš„ CHECK(status IN (..., 'cancelled'))
    - å¤åˆ¶æ•°æ®
    - æ›¿æ¢æ—§è¡¨
    - é‡å»ºç´¢å¼•ï¼ˆæœ¬æ–‡ä»¶å…¶ä»–é€»è¾‘ä¹Ÿä¼š CREATE INDEX IF NOT EXISTS å…œåº•ï¼‰
    """
    cursor.execute("SELECT sql FROM sqlite_master WHERE type='table' AND name='tasks'")
    row = cursor.fetchone()
    if not row or not row[0]:
        return

    create_sql = row[0]
    if "status IN ('pending', 'done', 'ignored', 'cancelled')" in create_sql:
        logger.debug("tasks.status CHECK å·²æ”¯æŒ cancelledï¼Œè·³è¿‡é‡å»º")
        return

    if "status IN ('pending', 'done', 'ignored')" not in create_sql:
        # æœªçŸ¥çš„çº¦æŸå½¢æ€ï¼šä¿å®ˆè·³è¿‡ï¼Œé¿å…ç ´åç”¨æˆ·è‡ªå®šä¹‰ schema
        logger.warning("tasks.status CHECK å½¢æ€æœªçŸ¥ï¼Œè·³è¿‡ cancelled è¿ç§»ï¼›è¯·æ‰‹åŠ¨æ£€æŸ¥ schema")
        return

    logger.info("å¼€å§‹è¿ç§» tasks.status CHECK ä»¥æ”¯æŒ cancelledï¼ˆé‡å»ºè¡¨ï¼‰...")
    cursor.execute("PRAGMA foreign_keys=OFF")
    try:
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS tasks_new (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                content TEXT NOT NULL,
                due_time TEXT,
                category TEXT,
                priority INTEGER CHECK(priority >= 1 AND priority <= 5) DEFAULT 3,
                status TEXT CHECK(status IN ('pending', 'done', 'ignored', 'cancelled')) DEFAULT 'pending',
                created_at TEXT NOT NULL DEFAULT (datetime('now')),
                last_notified_at TEXT,
                notification_count INTEGER DEFAULT 0
            )
        """)

        # å¤åˆ¶æ•°æ®ï¼ˆä¿æŒåŸæœ‰å­—æ®µï¼‰
        cursor.execute("""
            INSERT INTO tasks_new (id, content, due_time, category, priority, status, created_at, last_notified_at, notification_count)
            SELECT id, content, due_time, category, priority, status, created_at, last_notified_at, notification_count
            FROM tasks
        """)

        cursor.execute("DROP TABLE tasks")
        cursor.execute("ALTER TABLE tasks_new RENAME TO tasks")

        logger.info("âœ… tasks.status CHECK å·²è¿ç§»æ”¯æŒ cancelled")
    finally:
        cursor.execute("PRAGMA foreign_keys=ON")


def verify_migration():
    """
    éªŒè¯è¿ç§»æ˜¯å¦æˆåŠŸï¼Œå¹¶æ‰“å°ç»“æœåˆ°ç»ˆç«¯å’Œæ—¥å¿—
    """
    tasks_columns = get_column_names("tasks")
    prefs_columns = get_column_names("preferences")
    memory_columns = get_column_names("memory_logs")
    
    required_fields = {
        "tasks": ["last_notified_at", "notification_count"],
        "preferences": ["created_at"],
        "memory_logs": ["is_processed"]
    }
    
    all_ok = True
    missing_fields = []
    
    for table, fields in required_fields.items():
        columns = get_column_names(table)
        for field in fields:
            if field not in columns:
                logger.error(f"âŒ {table}.{field} å­—æ®µè¿ç§»å¤±è´¥")
                missing_fields.append(f"{table}.{field}")
                all_ok = False
            else:
                logger.debug(f"âœ… {table}.{field} å­—æ®µéªŒè¯é€šè¿‡")
    
    # æ‰“å°åˆ°ç»ˆç«¯ï¼ˆç”¨æˆ·å¯è§ï¼‰
    print("=" * 50)
    print("ğŸ“Š æ•°æ®åº“è¿ç§»éªŒè¯ç»“æœ")
    print("=" * 50)
    print(f"tasks è¡¨å­—æ®µ ({len(tasks_columns)} ä¸ª):")
    print(f"  {', '.join(tasks_columns)}")
    print(f"\npreferences è¡¨å­—æ®µ ({len(prefs_columns)} ä¸ª):")
    print(f"  {', '.join(prefs_columns)}")
    print(f"\nmemory_logs è¡¨å­—æ®µ ({len(memory_columns)} ä¸ª):")
    print(f"  {', '.join(memory_columns)}")
    print("=" * 50)
    
    if all_ok:
        logger.info("âœ… æ•°æ®åº“è¿ç§»éªŒè¯é€šè¿‡")
        print("âœ… æ‰€æœ‰å­—æ®µè¿ç§»æˆåŠŸï¼")
    else:
        logger.error(f"âŒ æ•°æ®åº“è¿ç§»éªŒè¯å¤±è´¥ï¼Œç¼ºå¤±å­—æ®µ: {', '.join(missing_fields)}")
        print(f"âŒ è¿ç§»éªŒè¯å¤±è´¥ï¼Œç¼ºå¤±å­—æ®µ: {', '.join(missing_fields)}")
    
    return all_ok


def record_interaction(content: str, sentiment: str = 'neutral', tag: Optional[str] = None) -> int:
    """
    ä¸€æ¬¡æ€§è®°å½•ç”¨æˆ·äº¤äº’åˆ° memory_logs è¡¨
    
    Args:
        content: äº¤äº’å†…å®¹
        sentiment: æƒ…æ„Ÿå€¾å‘ ('positive', 'neutral', 'negative')
        tag: ä¸Šä¸‹æ–‡æ ‡ç­¾ (å¦‚: 'work', 'life', 'idle')
    
    Returns:
        æ’å…¥è®°å½•çš„ ID
    """
    if sentiment not in ('positive', 'neutral', 'negative'):
        raise ValueError(f"sentiment å¿…é¡»æ˜¯ 'positive', 'neutral' æˆ– 'negative'ï¼Œå½“å‰å€¼: {sentiment}")
    
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO memory_logs (content, sentiment, context_tag, timestamp)
            VALUES (?, ?, ?, ?)
        """, (content, sentiment, tag, get_current_time()))
        conn.commit()
        return cursor.lastrowid


def update_interaction(record_id: int, sentiment: str, tag: Optional[str] = None):
    """
    æ›´æ–°å·²å­˜åœ¨çš„äº¤äº’è®°å½•ï¼ˆç”¨äºä¿®å¤é‡å¤è®°å½•é—®é¢˜ï¼‰
    
    Args:
        record_id: è¦æ›´æ–°çš„è®°å½• ID
        sentiment: æƒ…æ„Ÿå€¾å‘ ('positive', 'neutral', 'negative')
        tag: ä¸Šä¸‹æ–‡æ ‡ç­¾ (å¦‚: 'work', 'life', 'idle')
    """
    if sentiment not in ('positive', 'neutral', 'negative'):
        raise ValueError(f"sentiment å¿…é¡»æ˜¯ 'positive', 'neutral' æˆ– 'negative'ï¼Œå½“å‰å€¼: {sentiment}")
    
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE memory_logs 
            SET sentiment = ?, context_tag = ?
            WHERE id = ?
        """, (sentiment, tag, record_id))
        conn.commit()


def update_habit(key: str, value: str, boost: float = 0.1, source: str = 'AIæ¨æ–­'):
    """
    æ›´æ–°æˆ–åˆ›å»ºç”¨æˆ·ä¹ æƒ¯åå¥½
    æ¯æ¬¡å‘ç°ç”¨æˆ·ç¬¦åˆæŸä¸ªä¹ æƒ¯æ—¶ï¼Œç»™ç½®ä¿¡åº¦åŠ åˆ†
    
    Args:
        key: ä¹ æƒ¯é”®å
        value: ä¹ æƒ¯å€¼
        boost: ç½®ä¿¡åº¦æå‡å¹…åº¦ï¼ˆé»˜è®¤ 0.1ï¼‰
        source: æ¥æº ('ç”¨æˆ·ç›´è¯´' æˆ– 'AIæ¨æ–­')
    """
    if not (0.0 <= boost <= 1.0):
        raise ValueError(f"boost å¿…é¡»åœ¨ 0.0 åˆ° 1.0 ä¹‹é—´ï¼Œå½“å‰å€¼: {boost}")
    
    if source not in ('ç”¨æˆ·ç›´è¯´', 'AIæ¨æ–­'):
        raise ValueError(f"source å¿…é¡»æ˜¯ 'ç”¨æˆ·ç›´è¯´' æˆ– 'AIæ¨æ–­'ï¼Œå½“å‰å€¼: {source}")
    
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        # æ£€æŸ¥è®°å½•æ˜¯å¦å­˜åœ¨
        cursor.execute("SELECT confidence FROM preferences WHERE key = ?", (key,))
        result = cursor.fetchone()
        
        if result:
            # æ›´æ–°ç°æœ‰è®°å½•ï¼šå¢åŠ ç½®ä¿¡åº¦ï¼ˆä½†ä¸è¶…è¿‡ 1.0ï¼‰
            current_confidence = result[0]
            new_confidence = min(1.0, current_confidence + boost)
            cursor.execute("""
                UPDATE preferences 
                SET value = ?, confidence = ?, source = ?, updated_at = ?
                WHERE key = ?
            """, (value, new_confidence, source, get_current_time(), key))
        else:
            # åˆ›å»ºæ–°è®°å½•ï¼šåˆå§‹ç½®ä¿¡åº¦ä»é…ç½®è¯»å– + boostï¼ˆä½†ä¸è¶…è¿‡ 1.0ï¼‰
            config = _get_config()
            initial_confidence_base = config.PL_HABIT_INITIAL_CONFIDENCE
            initial_confidence = min(1.0, initial_confidence_base + boost)
            now = get_current_time()
            cursor.execute("""
                INSERT INTO preferences (key, value, confidence, source, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (key, value, initial_confidence, source, now, now))
        
        conn.commit()


def get_high_confidence_prefs(threshold: float = 0.7) -> List[Dict[str, Any]]:
    """
    è·å–é«˜ç½®ä¿¡åº¦çš„ç”¨æˆ·åå¥½ä¹ æƒ¯ï¼Œç”¨äºå†³ç­–
    
    Args:
        threshold: ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé»˜è®¤ 0.7ï¼Œå³ 70%ï¼‰
    
    Returns:
        é«˜ç½®ä¿¡åº¦åå¥½åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« key, value, confidence, source, updated_at
    """
    if not (0.0 <= threshold <= 1.0):
        raise ValueError(f"threshold å¿…é¡»åœ¨ 0.0 åˆ° 1.0 ä¹‹é—´ï¼Œå½“å‰å€¼: {threshold}")
    
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT key, value, confidence, source, updated_at, created_at
            FROM preferences
            WHERE confidence >= ?
            ORDER BY confidence DESC, updated_at DESC
        """, (threshold,))
        
        results = cursor.fetchall()
        return [
            {
                'key': row[0],
                'value': row[1],
                'confidence': row[2],
                'source': row[3],
                'updated_at': row[4],
                'created_at': row[5] if len(row) > 5 else None
            }
            for row in results
        ]


# é¢å¤–çš„å®ç”¨å‡½æ•°

def get_all_tasks(status: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    è·å–æ‰€æœ‰ä»»åŠ¡ï¼Œå¯é€‰æ‹©æ€§è¿‡æ»¤çŠ¶æ€
    
    Args:
        status: å¯é€‰çš„çŠ¶æ€è¿‡æ»¤ ('pending', 'done', 'ignored')
    
    Returns:
        ä»»åŠ¡åˆ—è¡¨
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        if status:
            cursor.execute("""
                SELECT id, content, due_time, category, priority, status, created_at, 
                       last_notified_at, notification_count
                FROM tasks
                WHERE status = ?
                ORDER BY priority DESC, due_time ASC, created_at ASC
            """, (status,))
        else:
            cursor.execute("""
                SELECT id, content, due_time, category, priority, status, created_at,
                       last_notified_at, notification_count
                FROM tasks
                ORDER BY priority DESC, due_time ASC, created_at ASC
            """)
        
        results = cursor.fetchall()
        return [
            {
                'id': row[0],
                'content': row[1],
                'due_time': row[2],
                'category': row[3],
                'priority': row[4],
                'status': row[5],
                'created_at': row[6],
                'last_notified_at': row[7],
                'notification_count': row[8] if len(row) > 8 else 0
            }
            for row in results
        ]


def add_task(content: str, due_time: Optional[str] = None, 
             category: Optional[str] = None, priority: int = 3) -> int:
    """
    æ·»åŠ æ–°ä»»åŠ¡
    
    Returns:
        æ–°åˆ›å»ºçš„ä»»åŠ¡ ID
    """
    if not (1 <= priority <= 5):
        raise ValueError(f"priority å¿…é¡»åœ¨ 1 åˆ° 5 ä¹‹é—´ï¼Œå½“å‰å€¼: {priority}")
    
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO tasks (content, due_time, category, priority, created_at)
            VALUES (?, ?, ?, ?, ?)
        """, (content, due_time, category, priority, get_current_time()))
        conn.commit()
        return cursor.lastrowid


def update_task_status(task_id: int, status: str):
    """
    æ›´æ–°ä»»åŠ¡çŠ¶æ€
    """
    if status not in ('pending', 'done', 'ignored', 'cancelled'):
        raise ValueError(f"status å¿…é¡»æ˜¯ 'pending', 'done', 'ignored' æˆ– 'cancelled'ï¼Œå½“å‰å€¼: {status}")
    
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE tasks 
            SET status = ?
            WHERE id = ?
        """, (status, task_id))
        conn.commit()


def cancel_task(task_id: int):
    """
    è½¯å–æ¶ˆä»»åŠ¡ï¼ˆç”¨äºâ€œå–æ¶ˆä¸Šä¸€ä¸ªâ€ç­‰åœºæ™¯ï¼‰
    ç­‰ä»·äº update_task_status(task_id, 'cancelled')
    """
    update_task_status(task_id, 'cancelled')


def update_task_content(task_id: int, content: str):
    """
    æ›´æ–°ä»»åŠ¡å†…å®¹ï¼ˆæ ‡é¢˜/æè¿°ï¼‰
    """
    if not content or not isinstance(content, str):
        raise ValueError("content ä¸èƒ½ä¸ºç©º")
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE tasks
            SET content = ?
            WHERE id = ?
        """, (content, task_id))
        conn.commit()
        logger.debug(f"å·²æ›´æ–°ä»»åŠ¡ {task_id} çš„å†…å®¹ä¸º: {content}")


def get_recent_tasks(status: str = 'pending', limit: int = 3) -> List[Dict[str, Any]]:
    """
    è·å–æœ€è¿‘åˆ›å»ºçš„ä»»åŠ¡åˆ—è¡¨ï¼ˆé»˜è®¤ï¼šæœ€è¿‘ 3 æ¡ pendingï¼‰
    ç”¨äº Interpreter çš„â€œä¸Šä¸€ä¸ªä»»åŠ¡/åˆšæ‰é‚£ä¸ªâ€ä¸Šä¸‹æ–‡å€™é€‰ã€‚
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT id, content, due_time, category, priority, status, created_at,
                   last_notified_at, notification_count
            FROM tasks
            WHERE status = ?
            ORDER BY created_at DESC
            LIMIT ?
        """, (status, limit))
        results = cursor.fetchall()
        return [
            {
                'id': row[0],
                'content': row[1],
                'due_time': row[2],
                'category': row[3],
                'priority': row[4],
                'status': row[5],
                'created_at': row[6],
                'last_notified_at': row[7],
                'notification_count': row[8] if len(row) > 8 else 0
            }
            for row in results
        ]


def update_task_notification_time(task_id: int):
    """
    æ›´æ–°ä»»åŠ¡çš„æœ€åé€šçŸ¥æ—¶é—´å’Œé€šçŸ¥æ¬¡æ•°
    ç”¨äº daemon.py è®°å½•é€šçŸ¥å†å²
    
    Args:
        task_id: ä»»åŠ¡ ID
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE tasks 
            SET last_notified_at = ?, 
                notification_count = notification_count + 1
            WHERE id = ?
        """, (get_current_time(), task_id))
        conn.commit()
        logger.debug(f"å·²æ›´æ–°ä»»åŠ¡ {task_id} çš„é€šçŸ¥æ—¶é—´å’Œæ¬¡æ•°")


def update_task_due_time(task_id: int, new_due_time: Optional[str]):
    """
    æ›´æ–°ä»»åŠ¡çš„åˆ°æœŸæ—¶é—´
    
    Args:
        task_id: ä»»åŠ¡ ID
        new_due_time: æ–°çš„åˆ°æœŸæ—¶é—´ï¼ˆISO 8601 æ ¼å¼ï¼Œå¯ä¸º Noneï¼‰
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE tasks 
            SET due_time = ?
            WHERE id = ?
        """, (new_due_time, task_id))
        conn.commit()
        logger.debug(f"å·²æ›´æ–°ä»»åŠ¡ {task_id} çš„åˆ°æœŸæ—¶é—´ä¸º: {new_due_time}")


def get_task_by_id(task_id: int) -> Optional[Dict[str, Any]]:
    """
    æ ¹æ® ID è·å–å•ä¸ªä»»åŠ¡
    
    Args:
        task_id: ä»»åŠ¡ ID
    
    Returns:
        ä»»åŠ¡å­—å…¸ï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µï¼‰ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT id, content, due_time, category, priority, status, created_at,
                   last_notified_at, notification_count
            FROM tasks
            WHERE id = ?
        """, (task_id,))
        
        row = cursor.fetchone()
        if not row:
            return None
        
        return {
            'id': row[0],
            'content': row[1],
            'due_time': row[2],
            'category': row[3],
            'priority': row[4],
            'status': row[5],
            'created_at': row[6],
            'last_notified_at': row[7],
            'notification_count': row[8] if len(row) > 8 else 0
        }


def get_upcoming_tasks(hours: int = 24, status: str = 'pending') -> List[Dict[str, Any]]:
    """
    è·å–æœªæ¥ N å°æ—¶å†…åˆ°æœŸçš„ä»»åŠ¡
    
    Args:
        hours: æœªæ¥å¤šå°‘å°æ—¶å†…ï¼ˆé»˜è®¤ 24 å°æ—¶ï¼‰
        status: ä»»åŠ¡çŠ¶æ€è¿‡æ»¤ï¼ˆé»˜è®¤ 'pending'ï¼‰
    
    Returns:
        å³å°†åˆ°æœŸçš„ä»»åŠ¡åˆ—è¡¨
    """
    # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒï¼Œæ›´ç¨³å¥
    now = datetime.now().astimezone()  # ä½¿ç”¨å¸¦æ—¶åŒºçš„å½“å‰æ—¶é—´
    future_time = now + timedelta(hours=hours)
    
    with get_db_connection() as conn:
        cursor = conn.cursor()
        # å…ˆæŸ¥è¯¢æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„ä»»åŠ¡ï¼ˆåªè¿‡æ»¤çŠ¶æ€å’Œ due_time éç©ºï¼‰
        cursor.execute("""
            SELECT id, content, due_time, category, priority, status, created_at,
                   last_notified_at, notification_count
            FROM tasks
            WHERE status = ?
              AND due_time IS NOT NULL
            ORDER BY due_time ASC, priority DESC
        """, (status,))
        
        results = cursor.fetchall()
        
        # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒå’Œè¿‡æ»¤
        filtered_tasks = []
        for row in results:
            due_time_str = row[2]
            if not due_time_str:
                continue
            
            try:
                # å°†æ•°æ®åº“æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡ï¼ˆå¤„ç†æ—¶åŒºï¼‰
                due_time_str_normalized = due_time_str.replace('Z', '+00:00')
                due_time_dt = datetime.fromisoformat(due_time_str_normalized)
                
                # ç¡®ä¿ due_time_dt æœ‰æ—¶åŒºä¿¡æ¯
                if due_time_dt.tzinfo is None:
                    # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾ä¸ºæœ¬åœ°æ—¶åŒº
                    due_time_dt = due_time_dt.replace(tzinfo=now.tzinfo)
                
                # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒ
                if now < due_time_dt <= future_time:
                    filtered_tasks.append({
                        'id': row[0],
                        'content': row[1],
                        'due_time': row[2],
                        'category': row[3],
                        'priority': row[4],
                        'status': row[5],
                        'created_at': row[6],
                        'last_notified_at': row[7],
                        'notification_count': row[8] if len(row) > 8 else 0
                    })
            except (ValueError, AttributeError) as e:
                # å¦‚æœæ—¶é—´æ ¼å¼è§£æå¤±è´¥ï¼Œè®°å½•æ—¥å¿—ä½†ç»§ç»­å¤„ç†å…¶ä»–ä»»åŠ¡
                logger.warning(f"æ— æ³•è§£æä»»åŠ¡ {row[0]} çš„ due_time '{due_time_str}': {e}")
                continue
        
        return filtered_tasks


def get_overdue_tasks(status: str = 'pending') -> List[Dict[str, Any]]:
    """
    è·å–å·²è¿‡æœŸçš„ä»»åŠ¡ï¼ˆæˆªæ­¢æ—¶é—´å·²è¿‡ä½†çŠ¶æ€ä»ä¸º pendingï¼‰
    
    Args:
        status: ä»»åŠ¡çŠ¶æ€è¿‡æ»¤ï¼ˆé»˜è®¤ 'pending'ï¼‰
    
    Returns:
        è¿‡æœŸä»»åŠ¡åˆ—è¡¨
    """
    # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒï¼Œæ›´ç¨³å¥
    now = datetime.now().astimezone()  # ä½¿ç”¨å¸¦æ—¶åŒºçš„å½“å‰æ—¶é—´
    
    with get_db_connection() as conn:
        cursor = conn.cursor()
        # å…ˆæŸ¥è¯¢æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„ä»»åŠ¡ï¼ˆåªè¿‡æ»¤çŠ¶æ€å’Œ due_time éç©ºï¼‰
        cursor.execute("""
            SELECT id, content, due_time, category, priority, status, created_at,
                   last_notified_at, notification_count
            FROM tasks
            WHERE status = ?
              AND due_time IS NOT NULL
            ORDER BY due_time ASC, priority DESC
        """, (status,))
        
        results = cursor.fetchall()
        
        # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒå’Œè¿‡æ»¤
        overdue_tasks = []
        for row in results:
            due_time_str = row[2]
            if not due_time_str:
                continue
            
            try:
                # å°†æ•°æ®åº“æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡ï¼ˆå¤„ç†æ—¶åŒºï¼‰
                due_time_str_normalized = due_time_str.replace('Z', '+00:00')
                due_time_dt = datetime.fromisoformat(due_time_str_normalized)
                
                # ç¡®ä¿ due_time_dt æœ‰æ—¶åŒºä¿¡æ¯
                if due_time_dt.tzinfo is None:
                    # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾ä¸ºæœ¬åœ°æ—¶åŒº
                    due_time_dt = due_time_dt.replace(tzinfo=now.tzinfo)
                
                # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒ
                if due_time_dt < now:
                    overdue_tasks.append({
                        'id': row[0],
                        'content': row[1],
                        'due_time': row[2],
                        'category': row[3],
                        'priority': row[4],
                        'status': row[5],
                        'created_at': row[6],
                        'last_notified_at': row[7],
                        'notification_count': row[8] if len(row) > 8 else 0
                    })
            except (ValueError, AttributeError) as e:
                # å¦‚æœæ—¶é—´æ ¼å¼è§£æå¤±è´¥ï¼Œè®°å½•æ—¥å¿—ä½†ç»§ç»­å¤„ç†å…¶ä»–ä»»åŠ¡
                logger.warning(f"æ— æ³•è§£æä»»åŠ¡ {row[0]} çš„ due_time '{due_time_str}': {e}")
                continue
        
        return overdue_tasks


def get_tasks_by_date_range(start_date: str, end_date: str, status: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    æŒ‰æ—¥æœŸèŒƒå›´æŸ¥è¯¢ä»»åŠ¡
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸï¼ˆISO æ ¼å¼ï¼Œå¦‚ '2026-01-18T00:00:00'ï¼‰
        end_date: ç»“æŸæ—¥æœŸï¼ˆISO æ ¼å¼ï¼Œå¦‚ '2026-01-19T23:59:59'ï¼‰
        status: å¯é€‰çš„çŠ¶æ€è¿‡æ»¤
    
    Returns:
        æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„ä»»åŠ¡åˆ—è¡¨
    """
    # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒï¼Œæ›´ç¨³å¥
    try:
        # å°†è¾“å…¥çš„æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡
        start_date_normalized = start_date.replace('Z', '+00:00')
        end_date_normalized = end_date.replace('Z', '+00:00')
        start_dt = datetime.fromisoformat(start_date_normalized)
        end_dt = datetime.fromisoformat(end_date_normalized)
        
        # ç¡®ä¿æœ‰æ—¶åŒºä¿¡æ¯
        if start_dt.tzinfo is None:
            start_dt = start_dt.replace(tzinfo=datetime.now().astimezone().tzinfo)
        if end_dt.tzinfo is None:
            end_dt = end_dt.replace(tzinfo=datetime.now().astimezone().tzinfo)
    except (ValueError, AttributeError) as e:
        logger.error(f"æ— æ³•è§£ææ—¥æœŸèŒƒå›´å‚æ•°: start_date={start_date}, end_date={end_date}, é”™è¯¯: {e}")
        return []
    
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        # å…ˆæŸ¥è¯¢æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„ä»»åŠ¡ï¼ˆåªè¿‡æ»¤çŠ¶æ€å’Œ due_time éç©ºï¼‰
        if status:
            cursor.execute("""
                SELECT id, content, due_time, category, priority, status, created_at,
                       last_notified_at, notification_count
                FROM tasks
                WHERE status = ?
                  AND due_time IS NOT NULL
                ORDER BY due_time ASC, priority DESC
            """, (status,))
        else:
            cursor.execute("""
                SELECT id, content, due_time, category, priority, status, created_at,
                       last_notified_at, notification_count
                FROM tasks
                WHERE due_time IS NOT NULL
                ORDER BY due_time ASC, priority DESC
            """)
        
        results = cursor.fetchall()
        
        # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒå’Œè¿‡æ»¤
        filtered_tasks = []
        for row in results:
            due_time_str = row[2]
            if not due_time_str:
                continue
            
            try:
                # å°†æ•°æ®åº“æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡ï¼ˆå¤„ç†æ—¶åŒºï¼‰
                due_time_str_normalized = due_time_str.replace('Z', '+00:00')
                due_time_dt = datetime.fromisoformat(due_time_str_normalized)
                
                # ç¡®ä¿ due_time_dt æœ‰æ—¶åŒºä¿¡æ¯
                if due_time_dt.tzinfo is None:
                    due_time_dt = due_time_dt.replace(tzinfo=start_dt.tzinfo)
                
                # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒ
                if start_dt <= due_time_dt <= end_dt:
                    filtered_tasks.append({
                        'id': row[0],
                        'content': row[1],
                        'due_time': row[2],
                        'category': row[3],
                        'priority': row[4],
                        'status': row[5],
                        'created_at': row[6],
                        'last_notified_at': row[7],
                        'notification_count': row[8] if len(row) > 8 else 0
                    })
            except (ValueError, AttributeError) as e:
                # å¦‚æœæ—¶é—´æ ¼å¼è§£æå¤±è´¥ï¼Œè®°å½•æ—¥å¿—ä½†ç»§ç»­å¤„ç†å…¶ä»–ä»»åŠ¡
                logger.warning(f"æ— æ³•è§£æä»»åŠ¡ {row[0]} çš„ due_time '{due_time_str}': {e}")
                continue
        
        return filtered_tasks


def get_all_preferences() -> List[Dict[str, Any]]:
    """
    è·å–æ‰€æœ‰åå¥½è®¾ç½®
    
    Returns:
        æ‰€æœ‰åå¥½åˆ—è¡¨
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT key, value, confidence, source, updated_at, created_at
            FROM preferences
            ORDER BY confidence DESC, updated_at DESC
        """)
        
        results = cursor.fetchall()
        return [
            {
                'key': row[0],
                'value': row[1],
                'confidence': row[2],
                'source': row[3],
                'updated_at': row[4],
                'created_at': row[5] if len(row) > 5 else None
            }
            for row in results
        ]


def get_recent_memory_logs(limit: int = 50, tag: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    è·å–æœ€è¿‘çš„äº¤äº’è®°å½•
    
    Args:
        limit: è¿”å›è®°å½•æ•°é‡é™åˆ¶
        tag: å¯é€‰çš„ä¸Šä¸‹æ–‡æ ‡ç­¾è¿‡æ»¤
    
    Returns:
        æœ€è¿‘çš„äº¤äº’è®°å½•åˆ—è¡¨
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        if tag:
            cursor.execute("""
                SELECT id, content, sentiment, context_tag, timestamp
                FROM memory_logs
                WHERE context_tag = ?
                ORDER BY timestamp DESC
                LIMIT ?
            """, (tag, limit))
        else:
            cursor.execute("""
                SELECT id, content, sentiment, context_tag, timestamp
                FROM memory_logs
                ORDER BY timestamp DESC
                LIMIT ?
            """, (limit,))
        
        results = cursor.fetchall()
        return [
            {
                'id': row[0],
                'content': row[1],
                'sentiment': row[2],
                'context_tag': row[3],
                'timestamp': row[4]
            }
            for row in results
        ]


def get_unprocessed_memory_logs(days: int = 7, limit: int = 100) -> List[Dict[str, Any]]:
    """
    è·å–æœªå¤„ç†çš„è®°å¿†æ—¥å¿—ï¼ˆç”¨äºåæ€è„šæœ¬ï¼‰
    
    Args:
        days: æŸ¥è¯¢æœ€è¿‘å¤šå°‘å¤©çš„è®°å½•ï¼ˆé»˜è®¤ 7 å¤©ï¼‰
        limit: æœ€å¤šè¿”å›å¤šå°‘æ¡ï¼ˆé»˜è®¤ 100 æ¡ï¼‰
    
    Returns:
        æœªå¤„ç†çš„è®°å¿†æ—¥å¿—åˆ—è¡¨
    """
    # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒï¼Œæ›´ç¨³å¥
    now = datetime.now().astimezone()
    cutoff_date = now - timedelta(days=days)
    
    with get_db_connection() as conn:
        cursor = conn.cursor()
        # å…ˆæŸ¥è¯¢æ‰€æœ‰æœªå¤„ç†çš„è®°å½•
        cursor.execute("""
            SELECT id, content, sentiment, context_tag, timestamp
            FROM memory_logs
            WHERE is_processed = 0
            ORDER BY timestamp ASC
        """)
        
        results = cursor.fetchall()
        
        # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒå’Œè¿‡æ»¤
        filtered_logs = []
        for row in results:
            timestamp_str = row[4]
            if not timestamp_str:
                continue
            
            try:
                # å°†æ•°æ®åº“æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡ï¼ˆå¤„ç†æ—¶åŒºï¼‰
                timestamp_str_normalized = timestamp_str.replace('Z', '+00:00')
                timestamp_dt = datetime.fromisoformat(timestamp_str_normalized)
                
                # ç¡®ä¿ timestamp_dt æœ‰æ—¶åŒºä¿¡æ¯
                if timestamp_dt.tzinfo is None:
                    timestamp_dt = timestamp_dt.replace(tzinfo=now.tzinfo)
                
                # åœ¨ Python å±‚è¿›è¡Œæ—¶é—´æ¯”è¾ƒ
                if timestamp_dt >= cutoff_date:
                    filtered_logs.append({
                        'id': row[0],
                        'content': row[1],
                        'sentiment': row[2],
                        'context_tag': row[3],
                        'timestamp': row[4]
                    })
                    
                    # è¾¾åˆ°é™åˆ¶æ•°é‡ååœæ­¢
                    if len(filtered_logs) >= limit:
                        break
            except (ValueError, AttributeError) as e:
                # å¦‚æœæ—¶é—´æ ¼å¼è§£æå¤±è´¥ï¼Œè®°å½•æ—¥å¿—ä½†ç»§ç»­å¤„ç†å…¶ä»–è®°å½•
                logger.warning(f"æ— æ³•è§£æè®°å¿†æ—¥å¿— {row[0]} çš„ timestamp '{timestamp_str}': {e}")
                continue
        
        return filtered_logs


def mark_memory_log_processed(log_id: int):
    """
    æ ‡è®°è®°å¿†æ—¥å¿—ä¸ºå·²å¤„ç†ï¼ˆç”¨äºåæ€è„šæœ¬ï¼‰
    
    Args:
        log_id: è®°å¿†æ—¥å¿— ID
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE memory_logs 
            SET is_processed = 1 
            WHERE id = ?
        """, (log_id,))
        conn.commit()
        logger.debug(f"å·²æ ‡è®°è®°å¿†æ—¥å¿— {log_id} ä¸ºå·²å¤„ç†")


def get_status() -> Dict[str, Any]:
    """
    è·å–æ•°æ®åº“çŠ¶æ€ä¿¡æ¯ï¼ˆè‡ªæ£€åŠŸèƒ½ï¼‰
    
    Returns:
        åŒ…å«å„ç§ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        # ç»Ÿè®¡ä»»åŠ¡æ•°é‡ï¼ˆæŒ‰çŠ¶æ€åˆ†ç»„ï¼‰
        cursor.execute("""
            SELECT status, COUNT(*) 
            FROM tasks 
            GROUP BY status
        """)
        task_status_counts = dict(cursor.fetchall())
        total_tasks = sum(task_status_counts.values())
        
        # ç»Ÿè®¡é«˜ç½®ä¿¡åº¦åå¥½æ•°é‡ï¼ˆä»é…ç½®è¯»å–é˜ˆå€¼ï¼‰
        config = _get_config()
        threshold = config.PL_HABIT_HIGH_CONFIDENCE_THRESHOLD
        cursor.execute("""
            SELECT COUNT(*) 
            FROM preferences 
            WHERE confidence >= ?
        """, (threshold,))
        high_conf_prefs_count = cursor.fetchone()[0]
        
        # ç»Ÿè®¡æ‰€æœ‰åå¥½æ•°é‡
        cursor.execute("SELECT COUNT(*) FROM preferences")
        total_prefs_count = cursor.fetchone()[0]
        
        # ç»Ÿè®¡è®°å¿†æ—¥å¿—æ•°é‡
        cursor.execute("SELECT COUNT(*) FROM memory_logs")
        total_memory_logs = cursor.fetchone()[0]
        
        # ç»Ÿè®¡æœ€è¿‘7å¤©çš„è®°å¿†æ—¥å¿—
        cursor.execute("""
            SELECT COUNT(*) 
            FROM memory_logs 
            WHERE timestamp >= datetime('now', '-7 days')
        """)
        recent_memory_logs = cursor.fetchone()[0]
        
        # è·å–å¹³å‡ç½®ä¿¡åº¦
        cursor.execute("""
            SELECT AVG(confidence) 
            FROM preferences
        """)
        avg_confidence = cursor.fetchone()[0]
        if avg_confidence is None:
            avg_confidence = 0.0
        
        # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶å¤§å°
        db_size = DB_PATH.stat().st_size if DB_PATH.exists() else 0
        db_size_mb = db_size / (1024 * 1024)
        
        return {
            'total_tasks': total_tasks,
            'task_status': task_status_counts,
            'high_conf_prefs': high_conf_prefs_count,
            'total_prefs': total_prefs_count,
            'total_memory_logs': total_memory_logs,
            'recent_memory_logs': recent_memory_logs,
            'avg_confidence': avg_confidence,
            'db_size_mb': db_size_mb,
            'is_healthy': True  # å¯ä»¥æ·»åŠ æ›´å¤šå¥åº·æ£€æŸ¥é€»è¾‘
        }


def print_status():
    """
    æ‰“å°å‹å¥½çš„çŠ¶æ€ä¿¡æ¯ï¼ˆç”¨äºå‘½ä»¤è¡Œï¼‰
    """
    try:
        status = get_status()
        
        print("=" * 50)
        print("ğŸ“Š Project Link æ•°æ®åº“çŠ¶æ€")
        print("=" * 50)
        
        # ä»»åŠ¡ç»Ÿè®¡
        print(f"\nğŸ“‹ ä»»åŠ¡ç®¡ç†")
        print(f"  æ€»ä»»åŠ¡æ•°: {status['total_tasks']}")
        if status['task_status']:
            for stat, count in status['task_status'].items():
                print(f"    - {stat}: {count} æ¡")
        else:
            print("    (æš‚æ— ä»»åŠ¡)")
        
        # åå¥½ç»Ÿè®¡
        print(f"\nğŸ§  ç”¨æˆ·åå¥½")
        print(f"  æ€»åå¥½æ•°: {status['total_prefs']}")
        print(f"  é«˜ç½®ä¿¡åº¦åå¥½ (â‰¥0.7): {status['high_conf_prefs']} ä¸ª")
        if status['total_prefs'] > 0:
            print(f"  å¹³å‡ç½®ä¿¡åº¦: {status['avg_confidence']:.2%}")
        
        # è®°å¿†ç»Ÿè®¡
        print(f"\nğŸ’­ è®°å¿†æ—¥å¿—")
        print(f"  æ€»è®°å½•æ•°: {status['total_memory_logs']}")
        print(f"  æœ€è¿‘7å¤©: {status['recent_memory_logs']} æ¡")
        
        # æ•°æ®åº“ä¿¡æ¯
        print(f"\nğŸ’¾ æ•°æ®åº“ä¿¡æ¯")
        print(f"  æ–‡ä»¶å¤§å°: {status['db_size_mb']:.2f} MB")
        print(f"  çŠ¶æ€: {'âœ… æ­£å¸¸' if status['is_healthy'] else 'âš ï¸  å¼‚å¸¸'}")
        
        # æˆé•¿æç¤º
        print(f"\nğŸŒ± æˆé•¿çŠ¶æ€")
        if status['high_conf_prefs'] == 0:
            print("  AI è¿˜åœ¨å­¦ä¹ ä¸­ï¼Œå°šæœªç¡®è®¤ä»»ä½•é«˜ç½®ä¿¡åº¦ä¹ æƒ¯...")
        elif status['high_conf_prefs'] < 3:
            print(f"  AI å·²ç¡®è®¤ {status['high_conf_prefs']} ä¸ªä¹ æƒ¯ï¼Œæ­£åœ¨æˆé•¿ä¸­...")
        elif status['high_conf_prefs'] < 10:
            print(f"  AI å·²ç¡®è®¤ {status['high_conf_prefs']} ä¸ªä¹ æƒ¯ï¼Œè¶Šæ¥è¶Šäº†è§£ä½ äº†ï¼")
        else:
            print(f"  AI å·²ç¡®è®¤ {status['high_conf_prefs']} ä¸ªä¹ æƒ¯ï¼Œéå¸¸äº†è§£ä½ çš„å·¥ä½œæ¨¡å¼ï¼")
        
        print("=" * 50)
        
    except Exception as e:
        logger.error(f"çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}", exc_info=True)
        print(f"âŒ çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
        print("   æç¤º: è¯·å…ˆè¿è¡Œ init_db() åˆå§‹åŒ–æ•°æ®åº“")


def clean_test_data():
    """
    æ¸…ç†æµ‹è¯•æ•°æ®ï¼ˆåˆ é™¤æ‰€æœ‰æ•°æ®ï¼‰
    æ³¨æ„ï¼šè¿™ä¼šåˆ é™¤æ‰€æœ‰æ•°æ®ï¼Œè¯·è°¨æ…ä½¿ç”¨
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        # åˆ é™¤æ‰€æœ‰æ•°æ®
        cursor.execute("DELETE FROM tasks")
        cursor.execute("DELETE FROM preferences")
        cursor.execute("DELETE FROM memory_logs")
        
        # é‡ç½®è‡ªå¢IDï¼ˆå¦‚æœ sqlite_sequence è¡¨å­˜åœ¨ï¼‰
        try:
            cursor.execute("DELETE FROM sqlite_sequence WHERE name IN ('tasks', 'preferences', 'memory_logs')")
        except sqlite3.OperationalError:
            # sqlite_sequence è¡¨å¯èƒ½ä¸å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
            pass
        
        conn.commit()
        logger.info("æµ‹è¯•æ•°æ®å·²æ¸…ç†å®Œæˆ")
        print("âœ… æ‰€æœ‰æ•°æ®å·²æ¸…ç†å®Œæˆ")


def clean_all_data():
    """
    æ¸…ç†æ‰€æœ‰æ•°æ®ï¼ˆå±é™©æ“ä½œï¼‰
    """
    confirm = input("âš ï¸  è­¦å‘Šï¼šè¿™å°†åˆ é™¤æ‰€æœ‰æ•°æ®ï¼ç¡®è®¤è¯·è¾“å…¥ 'yes': ")
    if confirm.lower() == 'yes':
        clean_test_data()
        logger.warning("æ‰€æœ‰æ•°æ®å·²æ¸…ç†ï¼ˆç”¨æˆ·ç¡®è®¤ï¼‰")
        print("âœ… æ‰€æœ‰æ•°æ®å·²æ¸…ç†")
    else:
        logger.info("æ¸…ç†æ“ä½œå·²å–æ¶ˆ")
        print("âŒ æ“ä½œå·²å–æ¶ˆ")


if __name__ == "__main__":
    import sys
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        if sys.argv[1] == "--status":
            # è‡ªæ£€æ¨¡å¼ï¼šæ˜¾ç¤ºæ•°æ®åº“çŠ¶æ€
            print_status()
        elif sys.argv[1] == "--clean":
            # æ¸…ç†æ¨¡å¼ï¼šåˆ é™¤æ‰€æœ‰æµ‹è¯•æ•°æ®
            clean_test_data()
        elif sys.argv[1] == "--clean-all":
            # æ¸…ç†æ‰€æœ‰æ•°æ®ï¼ˆå±é™©æ“ä½œï¼‰
            clean_all_data()
        elif sys.argv[1] == "--test":
            # æµ‹è¯•æ¨¡å¼ï¼šè¿è¡Œæµ‹è¯•ä»£ç ï¼ˆä¼šåˆ›å»ºæµ‹è¯•æ•°æ®ï¼‰
            logger.info("å¼€å§‹è¿è¡Œæ•°æ®åº“æµ‹è¯•")
            print("åˆå§‹åŒ–æ•°æ®åº“...")
            init_db()
            
            # æµ‹è¯•è®°å½•äº¤äº’
            record_interaction("ç”¨æˆ·å®Œæˆäº†å·¥ä½œé¡¹ç›®", "positive", "work")
            record_interaction("ç”¨æˆ·æ„Ÿåˆ°ç–²æƒ«", "negative", "life")
            logger.debug("æµ‹è¯•è®°å½•äº¤äº’å®Œæˆ")
            
            # æµ‹è¯•æ›´æ–°ä¹ æƒ¯
            update_habit("morning_routine", "å–å’–å•¡", boost=0.2)
            update_habit("morning_routine", "å–å’–å•¡", boost=0.1)  # å†æ¬¡ç¡®è®¤ï¼Œç½®ä¿¡åº¦æå‡
            update_habit("work_hours", "9-18", boost=0.15, source="ç”¨æˆ·ç›´è¯´")
            logger.debug("æµ‹è¯•æ›´æ–°ä¹ æƒ¯å®Œæˆ")
            
            # æµ‹è¯•è·å–é«˜ç½®ä¿¡åº¦åå¥½
            high_conf_prefs = get_high_confidence_prefs(threshold=0.6)
            print("\né«˜ç½®ä¿¡åº¦åå¥½:")
            for pref in high_conf_prefs:
                print(f"  {pref['key']}: {pref['value']} (ç½®ä¿¡åº¦: {pref['confidence']:.2f})")
            
            logger.info("æ•°æ®åº“æ¨¡å—æµ‹è¯•å®Œæˆ")
            print("\næ•°æ®åº“æ¨¡å—æµ‹è¯•å®Œæˆï¼")
            print("\næç¤º: ä½¿ç”¨ 'python database.py --status' æŸ¥çœ‹æ•°æ®åº“çŠ¶æ€")
            print("æç¤º: ä½¿ç”¨ 'python database.py --clean' æ¸…ç†æµ‹è¯•æ•°æ®")
        else:
            print("ç”¨æ³•:")
            print("  python database.py --status      # æŸ¥çœ‹æ•°æ®åº“çŠ¶æ€")
            print("  python database.py --test        # è¿è¡Œæµ‹è¯•ï¼ˆä¼šåˆ›å»ºæµ‹è¯•æ•°æ®ï¼‰")
            print("  python database.py --clean       # æ¸…ç†æµ‹è¯•æ•°æ®")
            print("  python database.py --clean-all   # æ¸…ç†æ‰€æœ‰æ•°æ®ï¼ˆå±é™©ï¼‰")
    else:
        # é»˜è®¤æ¨¡å¼ï¼šåªåˆå§‹åŒ–æ•°æ®åº“ï¼Œä¸åˆ›å»ºæµ‹è¯•æ•°æ®
        logger.info("æ•°æ®åº“æ¨¡å—å¯åŠ¨ï¼ˆé»˜è®¤æ¨¡å¼ï¼‰")
        print("åˆå§‹åŒ–æ•°æ®åº“...")
        init_db()
        logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
        print("\næç¤º:")
        print("  - ä½¿ç”¨ 'python database.py --status' æŸ¥çœ‹æ•°æ®åº“çŠ¶æ€")
        print("  - ä½¿ç”¨ 'python database.py --test' è¿è¡Œæµ‹è¯•ï¼ˆä¼šåˆ›å»ºæµ‹è¯•æ•°æ®ï¼‰")

